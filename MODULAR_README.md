# Modular DSO Framework: Universal Data Variant Support

The Modular Deep Symbolic Optimization (DSO) framework provides automatic detection and handling of different data structures, from simple scalar relationships to complex tensor operations. The system automatically configures itself to handle:

- **Scalar (SISO)**: Single input, single output
- **Vector Input (MISO)**: Multiple inputs, single output  
- **Vector Output (SIMO)**: Single input, multiple outputs
- **Vector Both (MIMO)**: Multiple inputs, multiple outputs
- **Matrix/Tensor**: Higher-dimensional data structures

## üöÄ Key Features

### Automatic Variant Detection
The framework automatically analyzes your data and determines the appropriate configuration:

```python
from dso.unified_dso import auto_fit

# The system automatically detects the data structure
result = auto_fit(your_dataset)
```

### Unified Interface
One simple interface handles all data variants:

```python
from dso.unified_dso import UnifiedDSO

# Create DSO instance
dso = UnifiedDSO()

# Fit automatically configures for your data
result = dso.fit(dataset)

# Make predictions
predictions = dso.predict(X_new)
```

### Modular Architecture
Each component automatically adapts to the detected data variant:

- **Data Handlers**: Variant-specific data processing
- **Program Executors**: Optimized execution for each variant
- **Policy Networks**: Adaptive sampling strategies
- **Task Configurations**: Automatic parameter adjustment

## üìä Supported Data Variants

### 1. Scalar (SISO)
Single input variable, single output variable.

```python
X = np.random.randn(100, 1)  # Single input
y = X.flatten() ** 2         # Single output
result = auto_fit((X, y))
```

**Example**: Finding `y = x¬≤` from data points.

### 2. Vector Input (MISO)
Multiple input variables, single output variable.

```python
X = np.random.randn(100, 3)              # 3 inputs
y = X[:, 0] * X[:, 1] + np.sin(X[:, 2])  # Single output
result = auto_fit((X, y))
```

**Example**: Finding `y = x‚ÇÅ*x‚ÇÇ + sin(x‚ÇÉ)` from multivariate data.

### 3. Vector Output (SIMO)
Single input variable, multiple output variables.

```python
X = np.random.randn(100, 1)  # Single input
y = np.column_stack([        # Multiple outputs
    X.flatten() ** 2,        # y‚ÇÅ = x¬≤
    np.sin(X.flatten()),     # y‚ÇÇ = sin(x)
    np.cos(X.flatten())      # y‚ÇÉ = cos(x)
])
result = auto_fit((X, y))
```

**Example**: Finding `[y‚ÇÅ, y‚ÇÇ, y‚ÇÉ] = [x¬≤, sin(x), cos(x)]` from data.

### 4. Vector Both (MIMO)
Multiple input variables, multiple output variables.

```python
X = np.random.randn(100, 3)  # 3 inputs
y = np.column_stack([        # 2 outputs
    X[:, 0] * X[:, 1],       # y‚ÇÅ = x‚ÇÅ*x‚ÇÇ
    np.sin(X[:, 2])          # y‚ÇÇ = sin(x‚ÇÉ)
])
result = auto_fit((X, y))
```

**Example**: Finding `[y‚ÇÅ, y‚ÇÇ] = [x‚ÇÅ*x‚ÇÇ, sin(x‚ÇÉ)]` from multivariate data.

### 5. Matrix/Tensor
Higher-dimensional input/output structures.

```python
X = np.random.randn(50, 2, 4)  # 2D matrices as input
y = np.sum(X, axis=2)          # Tensor operation
result = auto_fit((X, y))
```

**Example**: Finding tensor operations on matrix data.

## üõ† Installation and Setup

### Requirements
- Python 3.8+
- NumPy
- TensorFlow 2.x
- Pandas (for CSV loading)
- Matplotlib (for visualization)

### Installation
```bash
# Install the modular DSO framework
cd dso_pkg
pip install -e .
```

### Quick Start
```python
from dso.unified_dso import auto_fit
import numpy as np

# Create sample data
X = np.random.randn(100, 2)
y = X[:, 0] * X[:, 1] + np.sin(X[:, 0])

# Run symbolic regression with automatic configuration
result = auto_fit((X, y))

# Access results
print(f"Best expression: {result['best_program'].str}")
print(f"Variant detected: {result['variant_info']['variant']}")
```

## üìñ Usage Examples

### Example 1: Automatic Detection
```python
from dso.unified_dso import auto_fit

# Different data structures
datasets = {
    'scalar': (np.random.randn(100, 1), np.random.randn(100)),
    'miso': (np.random.randn(100, 3), np.random.randn(100)),
    'mimo': (np.random.randn(100, 3), np.random.randn(100, 2))
}

for name, dataset in datasets.items():
    print(f"\\nProcessing {name} dataset...")
    result = auto_fit(dataset, training={'n_samples': 5000})
    print(f"Detected: {result['variant_info']['variant']}")
    print(f"Expression: {result['best_program'].str}")
```

### Example 2: CSV Data Loading
```python
# CSV file with columns: x1, x2, x3, y1, y2
# Automatically detects inputs (x*) and outputs (y*)
result = auto_fit("your_data.csv")
```

### Example 3: Multi-Output Strategies
```python
from dso.unified_dso import auto_fit

# MIMO data
X = np.random.randn(100, 3)
y = np.random.randn(100, 2)

# Different strategies for multi-output
strategies = ['replicate', 'independent', 'shared']

for strategy in strategies:
    result = auto_fit(
        (X, y),
        **{'policy.multi_output_strategy': strategy}
    )
    print(f"{strategy}: {result['best_program'].str}")
```

### Example 4: Custom Configuration
```python
from dso.unified_dso import UnifiedDSO

# Create DSO with custom configuration
dso = UnifiedDSO(config_template="config_modular.json")

# Fit with custom parameters
result = dso.fit(
    dataset=(X, y),
    training={'n_samples': 50000, 'batch_size': 500},
    task={'function_set': ['add', 'mul', 'sin', 'cos']},
    policy={'multi_output_strategy': 'independent'}
)

# Evaluate on new data
accuracy = dso.evaluate(X_test, y_test)
```

## ‚öôÔ∏è Configuration

### Automatic Configuration
The system automatically configures parameters based on detected variant:

- **Scalar**: Simple single-program sampling
- **MISO**: Standard multi-input handling
- **SIMO/MIMO**: Multi-output strategies and evaluation
- **Tensor**: Specialized tensor operations

### Manual Configuration
Override automatic settings using configuration files or parameters:

```python
# Load custom configuration
dso = UnifiedDSO(config_template="config_modular.json")

# Or override specific parameters
result = auto_fit(
    dataset,
    policy={'multi_output_strategy': 'independent'},
    training={'n_samples': 100000},
    task={'function_set': ['add', 'mul', 'div', 'sin']}
)
```

### Multi-Output Strategies

1. **Replicate**: One program used for all outputs
   - Fast and simple
   - Good for related outputs

2. **Independent**: Separate programs for each output
   - More flexible
   - Better for unrelated outputs

3. **Shared**: Hybrid approach with shared components
   - Balances efficiency and flexibility
   - Good for partially related outputs

## üîß Architecture Overview

### Core Components

1. **Data Type Detection** (`dso.core.data_types`)
   - Automatic variant detection
   - Shape analysis and validation
   - Handler selection

2. **Modular Tasks** (`dso.task.regression.modular_regression`)
   - Variant-specific task configuration
   - Automatic data preparation
   - Multi-output evaluation

3. **Modular Programs** (`dso.core.modular_program`)
   - Adaptive program execution
   - Multi-output program management
   - Executor selection

4. **Modular Policies** (`dso.core.modular_policy`)
   - Strategy-based sampling
   - Multi-output program generation
   - Variant-specific optimization

5. **Unified Interface** (`dso.unified_dso`)
   - Single entry point
   - Automatic configuration
   - Convenience functions

### Data Flow

```
Input Data ‚Üí Variant Detection ‚Üí Component Configuration ‚Üí Training ‚Üí Results
     ‚Üì              ‚Üì                      ‚Üì                  ‚Üì         ‚Üì
  X, y arrays   DataShape &         Task, Policy,       DSO Training  Best
               DataHandler         Program, etc.         Loop         Programs
```

## üß™ Testing

### Run Tests
```bash
# Run all tests
python tests/test_modular_system.py

# Run demo
python examples/modular_dso_demo.py
```

### Test Coverage
- Data variant detection
- Handler creation and execution
- Task configuration
- Program execution
- Multi-output strategies
- Error handling
- Backward compatibility

## üìà Performance

### Benchmarks
The modular system maintains performance while adding flexibility:

- **Scalar**: No overhead compared to original DSO
- **MISO**: Minimal overhead (~5%)
- **MIMO**: Scales linearly with number of outputs
- **Tensor**: Optimized for high-dimensional data

### Memory Usage
- Efficient caching of variant-specific configurations
- Lazy initialization of components
- Memory-optimized tensor operations

## üîÑ Backward Compatibility

The modular system is fully backward compatible:

```python
# Original DSO code still works
from dso import DeepSymbolicOptimizer
from dso.task.regression.regression import RegressionTask

# Existing configurations and datasets work unchanged
task = RegressionTask(dataset="Nguyen-1")
dso = DeepSymbolicOptimizer(config)
```

## ü§ù Contributing

### Adding New Variants
1. Create new `DataHandler` subclass
2. Implement `ProgramExecutor` for the variant
3. Add detection logic to `DataShape`
4. Register handler in `DataTypeDetector`
5. Add tests and examples

### Example: Adding New Variant
```python
class CustomHandler(DataHandler):
    def prepare_data(self, X, y):
        # Custom data preparation
        return X, y
    
    def execute_program(self, program, X):
        # Custom execution logic
        return program.custom_execute(X)
    
    def compute_reward(self, y_true, y_pred):
        # Custom reward computation
        return custom_metric(y_true, y_pred)

# Register the handler
DataTypeDetector.register_handler(DataVariant.CUSTOM, CustomHandler)
```

## üìö API Reference

### Main Classes

#### `UnifiedDSO`
Main interface for symbolic regression.

```python
dso = UnifiedDSO(config_template=None, verbose=True)
result = dso.fit(dataset, **kwargs)
predictions = dso.predict(X)
metrics = dso.evaluate(X, y)
```

#### `ModularRegressionTask`
Regression task with automatic variant detection.

```python
task = ModularRegressionTask(dataset, **config)
reward = task.reward_function(program)
evaluation = task.evaluate(program)
```

#### `DataShape`
Data structure analysis and variant detection.

```python
data_shape = DataShape(X, y)
print(data_shape.variant)
print(data_shape.summary())
```

### Convenience Functions

```python
# Automatic fitting
result = auto_fit(dataset, **kwargs)

# Variant-specific functions
result = fit_scalar(dataset, **kwargs)
result = fit_mimo(dataset, strategy='independent', **kwargs)
result = fit_tensor(dataset, **kwargs)

# Detection only
data_shape, handler = auto_detect_data_structure(X, y)
```

## üêõ Troubleshooting

### Common Issues

1. **Shape Mismatch Errors**
   ```python
   # Ensure X and y have compatible shapes
   assert X.shape[0] == y.shape[0]  # Same number of samples
   ```

2. **Memory Issues with Large Tensors**
   ```python
   # Use smaller batch sizes for tensor data
   result = auto_fit(dataset, training={'batch_size': 50})
   ```

3. **Strategy Selection for MIMO**
   ```python
   # Try different strategies if one fails
   strategies = ['replicate', 'independent', 'shared']
   for strategy in strategies:
       try:
           result = auto_fit(dataset, **{'policy.multi_output_strategy': strategy})
           break
       except Exception:
           continue
   ```

### Debug Mode
```python
# Enable verbose output for debugging
dso = UnifiedDSO(verbose=True)
result = dso.fit(dataset, debug=1)
```

## üìú License

This modular DSO framework is released under the same license as the original DSO project.

## üôè Acknowledgments

Built upon the original Deep Symbolic Optimization framework. The modular extensions maintain full compatibility while adding powerful new capabilities for handling diverse data structures.

---

For more examples and detailed documentation, see the `examples/` directory and the comprehensive test suite in `tests/`.
